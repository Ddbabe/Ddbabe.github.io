define({ entries : {
    "8628914": {
        "abstract": "This paper describes a novel hierarchical reinforcement learning (HRL) algorithm for training an autonomous agent to play a dungeon crawler game. As opposed to most previous HRL frameworks, the proposed HRL system does not contain complex actions that take multiple time steps. Instead there is a hierarchy of behaviours which can either execute an action or delegate the decision to a sub-behaviour lower in the hierarchy. The actions or sub-behaviours are chosen by learning the estimated cumulative reward. Since each action only takes one time step and the system starts at the top of the hierarchy at every time step, the system is able to dynamically react to changes in its environment. The developed dungeon crawler game requires the agent to take keys, open doors, and go to the exit while evading or fighting with enemy units. Based on these tasks, behaviours are constructed and trained with a combination of multi-layer perceptrons and Q-learning. The system also uses a kind of multi-bjective learning that allows multiple parts of the hierarchy to simultaneously learn from a chosen action using their own reward function. The performance of the system is compared to an agent using MaxQ-learning that shares a similar overall design. The results show that the proposed dynamic HRL (dHRL) system yields much higher scores and win rates in different game levels and is able to learn to perform very well with only 500 training games.",
        "author": "Niel, Remi and Wiering, Marco A.",
        "booktitle": "2018 IEEE Symposium Series on Computational Intelligence (SSCI)",
        "doi": "10.1109/SSCI.2018.8628914",
        "keywords": "type:Applications in Game Systems",
        "pages": "1159-1166",
        "series": "IEEE SSCI",
        "title": "Hierarchical Reinforcement Learning for Playing a Dynamic Dungeon Crawler Game",
        "type": "INPROCEEDINGS",
        "year": "2018"
    },
    "Abs-2012-01914": {
        "abstract": "In this paper we introduce DeepCrawl, a fully-playable Roguelike prototype for iOS and Android in which all agents are controlled by policy networks trained using Deep Reinforcement Learning (DRL). Our aim is to understand whether recent advances in DRL can be used to develop convincing behavioral models for non-player characters in videogames. We begin with an analysis of requirements that such an AI system should satisfy in order to be practically applicable in video game development, and identify the elements of the DRL model used in the DeepCrawl prototype. The successes and limitations of DeepCrawl are documented through a series of playability tests performed on the final game. We believe that the techniques we propose offer insight into innovative new avenues for the development of behaviors for non-player characters in video games, as they offer the potential to overcome critical issues with",
        "author": "Alessandro Sestini and Alexander Kuhnle and Andrew D. Bagdanov",
        "bibsource": "dblp computer science bibliography, https://dblp.org",
        "biburl": "https://dblp.org/rec/journals/corr/abs-2012-01914.bib",
        "eprint": "2012.01914",
        "eprinttype": "arXiv",
        "journal": "CoRR",
        "keywords": "type:Applications in Game Systems",
        "series": "EMNLP",
        "timestamp": "Fri, 04 Dec 2020 12:07:23 +0100",
        "title": "DeepCrawl: Deep Reinforcement Learning for Turn-based Strategy Games",
        "type": "article",
        "url": "https://arxiv.org/abs/2012.01914",
        "volume": "abs/2012.01914",
        "year": "2020"
    },
    "Callison_Burch_2022": {
        "abstract": "AI researchers have posited Dungeons and Dragons (D&D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D&D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the game play. We train a large language model (LM) to generate the next game turn, conditioning it on different information. The LM can respond as a particular character or as the player who runs the game--i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output.",
        "author": "Callison-Burch, Chris and Tomar, Gaurav Singh and Martin, Lara and Ippolito, Daphne and Bailis, Suma and Reitter, David",
        "booktitle": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
        "doi": "10.18653/v1/2022.emnlp-main.637",
        "keywords": "type:Player Experience and Interaction",
        "pages": "9379\u20139393",
        "publisher": "Association for Computational Linguistics",
        "series": "EMNLP",
        "title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
        "type": "inproceedings",
        "url": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.637",
        "year": "2022"
    },
    "Farrokhi-MalekiZhao-2024": {
        "abstract": "Procedural Content Generation (PCG) is defined as the automatic creation of game content using algorithms. PCG has a long history in both the game industry and the academic world. It can increase player engagement and ease the work of game designers. While recent advances in deep learning approaches in PCG have enabled researchers and practitioners to create more sophisticated content, it is the arrival of Large Language Models (LLMs) that truly disrupted the trajectory of PCG advancement. This survey explores the differences between various algorithms used for PCG, including search-based methods, machine learning-based methods, other frequently used methods (e.g., noise functions), and the newcomer, LLMs. We also provide a detailed discussion on combined methods. Furthermore, we compare these methods based on the type of content they generate and the publication dates of their respective papers. Finally, we identify gaps in the existing academic work and suggest possible directions for future research. number",
        "author": "Farrokhi Maleki, Mahdi and Zhao, Richard",
        "doi": "10.1609/aiide.v20i1.31877",
        "journal": "Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment",
        "keywords": "type:Applications in Game Systems",
        "month": "Nov.",
        "pages": "167-178",
        "series": "AIIDE",
        "title": "Procedural Content Generation in Games: A Survey with Insights on Emerging LLM Integration",
        "type": "article",
        "url": "https://ojs.aaai.org/index.php/AIIDE/article/view/31877",
        "volume": "20",
        "year": "2024"
    },
    "Li_Riedl_2010": {
        "abstract": "Role-playing games, and other types of contemporary video games, usually contain a main storyline consisting of several causally related quests. As players have different motivations, tastes and preferences, it can be beneficial to customize game plotlines. In this paper, we present an offline algorithm for adapting human-authored game plotlines for computer role-playing games to suit the unique needs of individual players, thereby customizing gaming experiences and enhancing re-playability. Our approach uses an plan refinement technique based on partial-order planning to (a) optimize the global structure of the plotline according to input from a player model, (b) maintain plotline coherence, and (c) facilitate authorial intent by preserving as much of the original plotline as possible. A theoretical analysis of the authorial leverage and a user study suggest the benefits of this approach.",
        "author": "Li, Boyang and Riedl, Mark",
        "doi": "10.1609/aiide.v6i1.12394",
        "journal": "Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment",
        "keywords": "type:AI Narrative Engine Design",
        "month": "Oct.",
        "number": "1",
        "pages": "45-50",
        "series": "AIIDE",
        "title": "An Offline Planning Approach to Game Plotline Adaptation",
        "type": "article",
        "url": "https://ojs.aaai.org/index.php/AIIDE/article/view/12394",
        "volume": "6",
        "year": "2010"
    },
    "Moser01022015": {
        "abstract": "This article reports an experimental study that investigated the effects of narrative structure and number of salient decision points in a role-playing game (RPG). Previous research has proposed various theories and frameworks and posited that a branching structure with increased complexity (i.e., more salient decision points) will improve player\u2019s enjoyment. However, no empirical study has been conducted to validate these statements. This research attempts to fill in this gap. Two hypotheses were developed based on prior research. In a controlled experiment, participants were asked to view prerecorded game play sessions based on which participant experiences were assessed. The experiment suggests that both narrative structure and number of salient decision points impact on game play experience of RPGs.",
        "author": "Christopher Moser and Xiaowen Fang",
        "doi": "10.1080/10447318.2014.986639",
        "eprint": "https://doi.org/10.1080/10447318.2014.986639",
        "journal": "International Journal of Human\u2013Computer Interaction",
        "keywords": "type:Player Experience and Interaction",
        "number": "2",
        "pages": "146--156",
        "publisher": "Taylor \\& Francis",
        "series": "International Journal of Human\u2013Computer Interaction",
        "title": "Narrative Structure and Player Experience in Role-Playing Games",
        "type": "article",
        "url": "https://doi.org/10.1080/10447318.2014.986639",
        "volume": "31",
        "year": "2015"
    },
    "Riedl2010": {
        "abstract": "Narrative, and in particular storytelling, is an important part of the human experience. Consequently, computational systems that can reason about narrative can be more effective communicators, entertainers, educators, and trainers. One of the central challenges in computational narrative reasoning is narrative generation, the automated creation of meaningful event sequences. There are many factors -- logical and aesthetic -- that contribute to the success of a narrative artifact. Central to this success is its understandability. We argue that the following two attributes of narratives are universal: (a) the logical causal progression of plot, and (b) character believability. Character believability is the perception by the audience that the actions performed by characters do not negatively impact the audience's suspension of disbelief. Specifically, characters must be perceived by the audience to be intentional agents. In this article, we explore the use of refinement search as a technique for solving the narrative generation problem -- to find a sound and believable sequence of character actions that transforms an initial world state into a world state in which goal propositions hold. We describe a novel refinement search planning algorithm -- the Intent-based Partial Order Causal Link (IPOCL) planner -- that, in addition to creating causally sound plot progression, reasons about character intentionality by identifying possible character goals that explain their actions and creating plan structures that explain why those characters commit to their goals. We present the results of an empirical evaluation that demonstrates that narrative plans generated by the IPOCL algorithm support audience comprehension of character intentions better than plans generated by conventional partial-order planners.",
        "author": "Riedl,  M. O. and Young,  R. M.",
        "doi": "10.1613/jair.2989",
        "issn": "1076-9757",
        "journal": "Journal of Artificial Intelligence Research",
        "keywords": "type:AI Narrative Engine Design",
        "month": "sep",
        "pages": "217\u2013268",
        "publisher": "AI Access Foundation",
        "series": "JAIR",
        "title": "Narrative Planning: Balancing Plot and Character",
        "type": "article",
        "url": "http://dx.doi.org/10.1613/jair.2989",
        "volume": "39",
        "year": "2010"
    },
    "Riedl2011": {
        "abstract": "Much research on artificial intelligence in games has been devoted to creating opponents that play competently against human players. We argue that the traditional goal of AI in games-to win the game-is    but one of several interesting goals to pursue. We promote the alternative goal of making the human player's play experience ``better,'' i.e., AI systems in games should reason about how to deliver the best possible experience within the context of the game. The key insight we offer is that approaching AI reasoning for games as ``storytelling reasoning'' makes this goal much more attainable. We present a framework for creating interactive narratives for entertainment purposes based on a type of agent called an experience manager. An experience manager is an intelligent computer agent that manipulates a virtual world to dynamically adapt the narrative content the player experiences, based on his or her actions and inferences about his or her preferred style of play. Following a theoretical perspective on game AI as a form of storytelling, we discuss the implications of such a perspective in the context of several AI technological approaches.",
        "author": "Riedl, Mark and Thue, David  and Bulitko, Vadim",
        "booktitle": "Artificial Intelligence for Computer Games",
        "doi": "10.1007/978-1-4419-8188-2_6",
        "editor": "Gonz{\\'a}lez-Calero, Pedro Antonio and G{\\'o}mez-Mart{\\'i}n, Marco Antonio",
        "isbn": "978-1-4419-8188-2",
        "keywords": "type:AI Narrative Engine Design",
        "pages": "125--150",
        "publisher": "Springer New York",
        "series": "Artificial Intelligence for Computer Games",
        "title": "Game AI as Storytelling",
        "type": "Inbook",
        "url": "https://doi.org/10.1007/978-1-4419-8188-2_6",
        "year": "2011"
    },
    "Riedl_Bulitko_2021": {
        "abstract": "  Game Artificial Intelligence (Game AI) is a sub-discipline of Artificial Intelligence (AI) and Machine Learning (ML) that explores the ways in which AI and ML can augment player experiences in computer games. Storytelling is an integral part of many modern computer games; within games stories create context, motivate the player, and move the action forward. Interactive Narrative is the use of AI to create and manage stories within games, creating the perception that the player is a character in a dynamically unfolding and responsive story. This paper introduces Game AI and focuses on the open research problems of Interactive Narrative.",
        "author": "Riedl, Mark and Bulitko, Vadim",
        "doi": "10.1609/aaai.v26i1.8447",
        "journal": "Proceedings of the AAAI Conference on Artificial Intelligence",
        "keywords": "type:AI Narrative Engine Design,other:Game AI, Interactive Narrative",
        "month": "Sep.",
        "number": "1",
        "pages": "2160-2165",
        "series": "AAAI",
        "title": "Interactive Narrative: A Novel Application of Artificial Intelligence for Computer Games",
        "type": "article",
        "url": "https://ojs.aaai.org/index.php/AAAI/article/view/8447",
        "volume": "26",
        "year": "2021"
    },
    "Rowe_Mott_Lester_2021": {
        "abstract": "  Recent years have witnessed growing interest in data-driven approaches to interactive narrative planning and drama management. Reinforcement learning techniques show particular promise because they can automatically induce and refine models for tailoring game events by optimizing reward functions that explicitly encode interactive narrative experiences\u2019 quality. Due to the inherently subjective nature of interactive narrative experience, designing effective reward functions is challenging. In this paper, we investigate the impacts of alternate formulations of reward in a reinforcement learning-based interactive narrative planner for the Crystal Island game environment. We formalize interactive narrative planning as a modular reinforcement-learning (MRL) problem. By decomposing interactive narrative planning into multiple independent sub-problems, MRL enables efficient induction of interactive narrative policies directly from a corpus of human players\u2019 experience data. Empirical analyses suggest that interactive narrative policies induced with MRL are likely to yield better player outcomes than heuristic or baseline policies. Furthermore, we observe that MRL-based interactive narrative planners are robust to alternate reward discount parameterizations.",
        "author": "Rowe, Jonathan and Mott, Bradford and Lester, James",
        "doi": "10.1609/aiide.v10i1.12733",
        "journal": "Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment",
        "keywords": "type:Player Experience and Interaction",
        "month": "Jun.",
        "number": "1",
        "pages": "160-166",
        "series": "AAAI",
        "title": "Optimizing Player Experience in Interactive Narrative Planning: A Modular Reinforcement Learning Approach",
        "type": "article",
        "url": "https://ojs.aaai.org/index.php/AIIDE/article/view/12733",
        "volume": "10",
        "year": "2021"
    }
}});